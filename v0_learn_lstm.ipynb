{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HYPER PARAM\n",
    "PROJECT_NAME = \"RobocupTrajectoryPrediction\"\n",
    "MODEL_NAME = \"LitBiLSTM_2\"\n",
    "GROUP_NAME = \"LitBiLSTM\"\n",
    "BATCH_SIZE = 512\n",
    "EPOCHS = 200\n",
    "HIDDEN_DIM = 256\n",
    "NUM_LAYER = 4\n",
    "LEARNING_RATE = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "import os\n",
    "\n",
    "import visualizer\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "import datasets\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from torch import nn\n",
    "import torchmetrics\n",
    "import pytorch_lightning as pl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_float32_matmul_precision(\"high\")\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = datasets.load_dataset(\n",
    "    \"ReonOhashi/RobocupTrajectoryPrediction_8team\",\n",
    "    revision=\"ab9aaf0feeb14402e112fb1bd94d26dd5d0ba507\",\n",
    ")\n",
    "dataset = dataset[\"train\"]\n",
    "train_raw, test_raw = dataset.train_test_split(test_size=0.2, seed=42).values()\n",
    "len(train_raw), len(test_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Union\n",
    "\n",
    "\n",
    "def swap_rl(df):\n",
    "    \"\"\"左右のチーム情報を交換\"\"\"\n",
    "    df = df.copy()\n",
    "    df[\"l_name\"], df[\"r_name\"] = df[\"r_name\"], df[\"l_name\"]\n",
    "\n",
    "    l_cols = [f\"l{i}_x\" for i in range(1, 12)] + [f\"l{i}_y\" for i in range(1, 12)]\n",
    "    r_cols = [f\"r{i}_x\" for i in range(1, 12)] + [f\"r{i}_y\" for i in range(1, 12)]\n",
    "\n",
    "    df[l_cols], df[r_cols] = df[r_cols].values, df[l_cols].values\n",
    "\n",
    "    # x座標を反転\n",
    "    df[\"b_x\"] *= -1\n",
    "    for i in range(1, 12):\n",
    "        df[f\"l{i}_x\"] *= -1\n",
    "        df[f\"r{i}_x\"] *= -1\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def to_df(arrs):\n",
    "    feature_columns = dataset.column_names\n",
    "    columns = [col for col in feature_columns if col != \"goal_type\"]\n",
    "    return [pd.DataFrame(arr, columns=columns).assign(goal_type=None) for arr in arrs]\n",
    "\n",
    "\n",
    "def to_np(dataset: datasets.arrow_dataset.Dataset):\n",
    "    # データをpd.DataFrameに変換\n",
    "    # goal_typeがgoal_lの場合はそのまま、goal_rの場合は左右を入れ替える\n",
    "    # goal_type列はその後削除\n",
    "    a = [pd.DataFrame(i) for i in tqdm(dataset, leave=True)]\n",
    "    a = [\n",
    "        i if i[\"goal_type\"].iloc[0] in [\"goal_l\", None] else swap_rl(i)\n",
    "        for i in tqdm(a, leave=True)\n",
    "    ]\n",
    "    a = [i.drop(columns=[\"goal_type\"]) for i in tqdm(a, leave=True)]\n",
    "    return np.stack(a)\n",
    "\n",
    "\n",
    "# Save to cache\n",
    "# train, test = to_np(train_raw), to_np(test_raw)\n",
    "# os.makedirs(\"/.cache/ohashi\", exist_ok=True)\n",
    "# joblib.dump((train, test), \"/.cache/ohashi/train_test.pkl\")\n",
    "train, test = joblib.load(\"/.cache/ohashi/train_test.pkl\")\n",
    "train: np.ndarray\n",
    "test: np.ndarray\n",
    "\n",
    "print(train.shape, test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove nan and inf\n",
    "print(train.shape, test.shape)  # (5708, 50, 49) (1424, 50, 49)\n",
    "\n",
    "train = train[~np.isnan(train).any(axis=(1, 2))]\n",
    "test = test[~np.isnan(test).any(axis=(1, 2))]\n",
    "\n",
    "print(train.shape, test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = train[:, :20, :], train[:, 20:, :]\n",
    "X_test, y_test = test[:, :20, :], test[:, 20:, :]\n",
    "\n",
    "print(X_train.shape, y_train.shape, X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EuclideanDistance(torchmetrics.Metric):\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.add_state(\"sum\", default=torch.tensor(0.0), dist_reduce_fx=\"sum\")\n",
    "        self.add_state(\"count\", default=torch.tensor(0), dist_reduce_fx=\"sum\")\n",
    "\n",
    "    def update(self, preds, target):\n",
    "        indices = torch.arange(2, 26, 2)  # [2, 4, 6, ..., 24]\n",
    "        final_preds = preds[:, -1, :]  # (b, 49)\n",
    "        final_target = target[:, -1, :]  # (b, 49)\n",
    "\n",
    "        errors = torch.sqrt(\n",
    "            (final_preds[:, indices] - final_target[:, indices]) ** 2\n",
    "            + (final_preds[:, indices + 1] - final_target[:, indices + 1]) ** 2\n",
    "        )\n",
    "        self.sum += torch.sum(errors)\n",
    "        self.count += errors.size(0)\n",
    "\n",
    "    def compute(self):\n",
    "        return self.sum / self.count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train, dtype=torch.float32)\n",
    "X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
    "y_test_tensor = torch.tensor(y_test, dtype=torch.float32)\n",
    "\n",
    "# TensorDataset と DataLoader の作成\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_dataset, batch_size=BATCH_SIZE, shuffle=True, pin_memory=True, num_workers=16\n",
    ")\n",
    "val_loader = DataLoader(\n",
    "    test_dataset, batch_size=BATCH_SIZE, shuffle=False, pin_memory=True, num_workers=16\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "from pytorch_lightning.loggers import WandbLogger\n",
    "\n",
    "\n",
    "class LitBiLSTM(pl.LightningModule):\n",
    "    def __init__(\n",
    "        self, input_dim, hidden_dim, output_dim, num_layers, seq_length, lr=0.001\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=input_dim,\n",
    "            hidden_size=hidden_dim,\n",
    "            num_layers=num_layers,\n",
    "            batch_first=True,\n",
    "            bidirectional=True,\n",
    "        )\n",
    "        self.fc = nn.Linear(hidden_dim * 2, output_dim * seq_length)\n",
    "        self.criterion = nn.MSELoss()\n",
    "        self.euclidean_distance = EuclideanDistance()\n",
    "        self.train_losses = []\n",
    "        self.val_losses = []\n",
    "\n",
    "    def forward(self, x):\n",
    "        out, _ = self.lstm(x)\n",
    "        last_out = out[:, -1, :]\n",
    "        output = self.fc(last_out)\n",
    "        return output.view(-1, 30, self.hparams.output_dim)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_hat = self(x)\n",
    "        loss = self.criterion(y_hat, y)\n",
    "        self.log(\"train_loss\", loss, on_step=False, on_epoch=True)\n",
    "        self.log(\n",
    "            \"train_euclidean_distance\",\n",
    "            self.euclidean_distance(y_hat, y),\n",
    "            on_step=False,\n",
    "            on_epoch=True,\n",
    "        )\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_hat = self(x)\n",
    "        loss = self.criterion(y_hat, y)\n",
    "        self.log(\"val_loss\", loss, on_step=False, on_epoch=True)\n",
    "        self.log(\n",
    "            \"val_euclidean_distance\",\n",
    "            self.euclidean_distance(y_hat, y),\n",
    "            on_step=False,\n",
    "            on_epoch=True,\n",
    "        )\n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=self.hparams.lr)\n",
    "        return optimizer\n",
    "\n",
    "\n",
    "# チェックポイントのコールバックを定義（val_euclidean_distanceが改善したときに保存）\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    monitor=\"val_euclidean_distance\",\n",
    "    dirpath=f\"checkpoints/{MODEL_NAME}\",\n",
    "    filename=\"bilstm-{epoch:02d}-{val_euclidean_distance:.4f}\",\n",
    "    save_top_k=3,\n",
    "    mode=\"min\",\n",
    ")\n",
    "\n",
    "wandb_logger = WandbLogger(\n",
    "    project=PROJECT_NAME,\n",
    "    log_model=True,\n",
    "    save_code=True,\n",
    "    save_dir=\"logs/\",\n",
    "    name=MODEL_NAME,\n",
    "    group=GROUP_NAME,\n",
    ")\n",
    "\n",
    "\n",
    "trainer = pl.Trainer(\n",
    "    max_epochs=EPOCHS,\n",
    "    accelerator=\"gpu\",\n",
    "    devices=1,\n",
    "    callbacks=[checkpoint_callback],\n",
    "    logger=wandb_logger,\n",
    ")\n",
    "\n",
    "\n",
    "X_train.shape  # b, 20, 49\n",
    "y_train.shape  # b, 30, 49\n",
    "\n",
    "input_dim = X_train.shape[2]\n",
    "hidden_dim = HIDDEN_DIM\n",
    "output_dim = y_train.shape[2]\n",
    "seq_length = y_train.shape[1]\n",
    "num_layers = NUM_LAYER\n",
    "learning_rate = LEARNING_RATE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LitBiLSTM(\n",
    "    input_dim, hidden_dim, output_dim, num_layers, seq_length, lr=learning_rate\n",
    ")\n",
    "trainer.fit(model, train_loader, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "best_model_path = checkpoint_callback.best_model_path\n",
    "model = LitBiLSTM.load_from_checkpoint(best_model_path)\n",
    "file_name = f\"{MODEL_NAME}_{time.strftime('%Y%m%d%H%M%S')}.pth\"\n",
    "\n",
    "os.makedirs(f\"models/{MODEL_NAME}\", exist_ok=True)\n",
    "torch.save(model.state_dict(), f\"models/{MODEL_NAME}/{file_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import visualizer\n",
    "from importlib import reload\n",
    "\n",
    "reload(visualizer)\n",
    "import visualizer\n",
    "\n",
    "\n",
    "def visualize_test(X, y, index=0):\n",
    "\n",
    "    X_test, y_test = X[index, :, :], y[index, :, :]\n",
    "    X_test = np.array([X_test])\n",
    "\n",
    "    X_test = torch.tensor(X_test, dtype=torch.float32).to(device)\n",
    "    y_test = torch.tensor(y_test, dtype=torch.float32).to(device)\n",
    "\n",
    "    model.to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        pred = model.forward(X_test)\n",
    "\n",
    "    pred = pred[0]\n",
    "    X_test = X_test[0]\n",
    "\n",
    "    X_test = X_test.cpu().numpy()\n",
    "    pred = pred.cpu().numpy()\n",
    "    y_test = y_test.cpu().numpy()\n",
    "\n",
    "    pred = np.concatenate([X_test, pred], axis=0)\n",
    "    y_test = np.concatenate([X_test, y_test], axis=0)\n",
    "\n",
    "    return visualizer.visualizer_np2(y_test, pred)\n",
    "\n",
    "\n",
    "import pathlib\n",
    "\n",
    "video_filepaths = []\n",
    "for i in range(10):\n",
    "    anim = visualize_test(X_test, y_test, index=i)\n",
    "    video_filename = f\"{MODEL_NAME}_{i}.gif\"\n",
    "    video_dir = pathlib.Path(\"videos\")\n",
    "    video_dir.mkdir(exist_ok=True)\n",
    "    anim.save(video_dir / video_filename, writer=\"pillow\", fps=10)\n",
    "    video_filepaths.append(video_dir / video_filename)\n",
    "\n",
    "wandb_logger.log_video(\"example\", [str(i) for i in video_filepaths])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "euclidean_distance = EuclideanDistance().to(device)\n",
    "\n",
    "error = 0\n",
    "model.eval()\n",
    "for X, y in tqdm(val_loader):\n",
    "    X, y = X.to(device), y.to(device)\n",
    "    with torch.no_grad():\n",
    "        pred = model.forward(X)\n",
    "    error += euclidean_distance(pred, y)\n",
    "print(error / len(val_loader))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
