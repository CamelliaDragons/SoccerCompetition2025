{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datasets\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option(\"display.max_columns\", None)\n",
    "pd.set_option(\"display.max_rows\", None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2150c9f3cfa34033b69548babde4a8bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/42 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "860a78fd950c4e35bb139c088e8aeac4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/42 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec972ad17b13499cbe7f956aaaa40fd4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading dataset shards:   0%|          | 0/36 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset = datasets.load_dataset(\n",
    "    \"ReonOhashi/RobocupTrajectoryPrediction_8team\",\n",
    "    revision=\"939d484d29b31c7f7389e451c830fa98fd942284\",\n",
    ")\n",
    "\n",
    "dataset = dataset[\"train\"]\n",
    "train_raw, test_raw = dataset.train_test_split(test_size=0.2, seed=42).values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(190079, 47520)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_raw), len(test_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MinMax:\n",
    "    def __init__(self, min, max):\n",
    "        self.min = min\n",
    "        self.max = max\n",
    "        if self.min >= self.max:\n",
    "            raise ValueError(\"min must be less than max\")\n",
    "\n",
    "    def __call__(self, x):\n",
    "        return (x - self.min) / (self.max - self.min)\n",
    "\n",
    "    def inverse(self, x):\n",
    "        return x * (self.max - self.min) + self.min\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f\"MinMax({self.min}, {self.max})\"\n",
    "\n",
    "\n",
    "def swap_rl(df):\n",
    "    df[\"l_name\"], df[\"r_name\"] = df[\"r_name\"], df[\"l_name\"]\n",
    "    df[\"b_x\"] *= -1\n",
    "\n",
    "    for i in range(1, 12):\n",
    "        l_x, r_x = f\"l{i}_x\", f\"r{i}_x\"\n",
    "        l_y, r_y = f\"l{i}_y\", f\"r{i}_y\"\n",
    "\n",
    "        df[l_x], df[r_x] = -df[r_x].values, -df[l_x].values\n",
    "        df[l_y], df[r_y] = df[r_y].values, df[l_y].values\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_and_merge_datasets(datas):\n",
    "    data_list = []\n",
    "    for data in datas:\n",
    "        df = pd.DataFrame(data)\n",
    "        if df.isnull().values.any():\n",
    "            continue\n",
    "        if not np.isfinite(df.select_dtypes(include=[np.number]).values).all():\n",
    "            continue\n",
    "        if df[\"goal_type\"].iloc[0] == \"goal_r\":\n",
    "            df = swap_rl(df)\n",
    "        data_list.append(df)\n",
    "    datas = pd.concat(data_list)\n",
    "    return datas\n",
    "\n",
    "\n",
    "def name_onehot(dfs):\n",
    "    for i in range(10):\n",
    "        dfs[f\"l_name_{i}\"] = dfs[\"l_name\"] == i\n",
    "        dfs[f\"r_name_{i}\"] = dfs[\"r_name\"] == i\n",
    "        dfs[f\"l_name_{i}\"] = (dfs[\"l_name\"] == i).astype(int)\n",
    "        dfs[f\"r_name_{i}\"] = (dfs[\"r_name\"] == i).astype(int)\n",
    "    return dfs\n",
    "\n",
    "\n",
    "def drop_unnecessary_columns(dfs):\n",
    "    dfs = dfs.drop(\n",
    "        columns=[\n",
    "            \"#\",\n",
    "            \"cycle\",\n",
    "            \"stopped\",\n",
    "            \"playmode\",\n",
    "            \"l_name\",\n",
    "            \"r_name\",\n",
    "            \"goal_type\",\n",
    "            \"l_score\",\n",
    "            \"r_score\",\n",
    "            \"l_pen_score\",\n",
    "            \"r_pen_score\",\n",
    "        ]\n",
    "    )\n",
    "    return dfs\n",
    "\n",
    "\n",
    "def min_max_normalize(dfs):\n",
    "    min_max_d = {col: MinMax(min(dfs[col]), max(dfs[col])) for col in dfs.columns}\n",
    "    for col in dfs.columns:\n",
    "        dfs[col] = min_max_d[col](dfs[col])\n",
    "    return dfs, min_max_d\n",
    "\n",
    "\n",
    "def revert_min_max_normalize(dfs, min_max_d):\n",
    "    for col in dfs.columns:\n",
    "        dfs[col] = min_max_d[col].inverse(dfs[col])\n",
    "    return dfs\n",
    "\n",
    "\n",
    "def divide_dataframe(dfs, df_size=50):\n",
    "    df_list = []\n",
    "\n",
    "    for i in range(0, len(dfs), df_size):\n",
    "        df = dfs.iloc[i : i + df_size]\n",
    "        df_list.append(df)\n",
    "    return df_list\n",
    "\n",
    "\n",
    "def list_to_numpy(dfs: list) -> np.ndarray:\n",
    "    cols = dfs[0].columns\n",
    "    return np.array([df.values for df in dfs]).astype(np.float32), cols\n",
    "\n",
    "\n",
    "def revert_numpy_from_list(dfs: np.ndarray, cols) -> list[pd.DataFrame]:\n",
    "    return [pd.DataFrame(df, columns=cols) for df in dfs]\n",
    "\n",
    "\n",
    "train = train_raw\n",
    "train = clean_and_merge_datasets(train)\n",
    "train = name_onehot(train)\n",
    "train = drop_unnecessary_columns(train)\n",
    "train, min_max_d = min_max_normalize(train)\n",
    "train = divide_dataframe(train)\n",
    "\n",
    "train, cols = list_to_numpy(train)\n",
    "\n",
    "os.makedirs(\"datas\", exist_ok=True)\n",
    "np.save(\"datas/train.npy\", train)\n",
    "np.save(\"datas/cols.npy\", cols)\n",
    "np.save(\"datas/min_max_d.npy\", min_max_d, allow_pickle=True)\n",
    "\n",
    "train = np.load(\"datas/train.npy\")\n",
    "cols = np.load(\"datas/cols.npy\", allow_pickle=True)\n",
    "min_max_d = np.load(\"datas/min_max_d.npy\", allow_pickle=True).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m test \u001b[38;5;241m=\u001b[39m test_raw\n\u001b[0;32m----> 2\u001b[0m test \u001b[38;5;241m=\u001b[39m \u001b[43mclean_and_merge_datasets\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m test \u001b[38;5;241m=\u001b[39m name_onehot(test)\n\u001b[1;32m      4\u001b[0m test \u001b[38;5;241m=\u001b[39m drop_unnecessary_columns(test)\n",
      "Cell \u001b[0;32mIn[6], line 9\u001b[0m, in \u001b[0;36mclean_and_merge_datasets\u001b[0;34m(datas)\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m np\u001b[38;5;241m.\u001b[39misfinite(df\u001b[38;5;241m.\u001b[39mselect_dtypes(include\u001b[38;5;241m=\u001b[39m[np\u001b[38;5;241m.\u001b[39mnumber])\u001b[38;5;241m.\u001b[39mvalues)\u001b[38;5;241m.\u001b[39mall():\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m----> 9\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgoal_type\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39miloc[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgoal_r\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m     10\u001b[0m     df \u001b[38;5;241m=\u001b[39m swap_rl(df)\n\u001b[1;32m     11\u001b[0m data_list\u001b[38;5;241m.\u001b[39mappend(df)\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/frame.py:4074\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4070\u001b[0m is_mi \u001b[38;5;241m=\u001b[39m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns, MultiIndex)\n\u001b[1;32m   4071\u001b[0m \u001b[38;5;66;03m# GH#45316 Return view if key is not duplicated\u001b[39;00m\n\u001b[1;32m   4072\u001b[0m \u001b[38;5;66;03m# Only use drop_duplicates with duplicates for performance\u001b[39;00m\n\u001b[1;32m   4073\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_mi \u001b[38;5;129;01mand\u001b[39;00m (\n\u001b[0;32m-> 4074\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_unique\u001b[49m\n\u001b[1;32m   4075\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\n\u001b[1;32m   4076\u001b[0m     \u001b[38;5;129;01mor\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mdrop_duplicates(keep\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m   4077\u001b[0m ):\n\u001b[1;32m   4078\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_item_cache(key)\n\u001b[1;32m   4080\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m is_mi \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mis_unique \u001b[38;5;129;01mand\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns:\n",
      "File \u001b[0;32mproperties.pyx:36\u001b[0m, in \u001b[0;36mpandas._libs.properties.CachedProperty.__get__\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/indexes/base.py:2346\u001b[0m, in \u001b[0;36mIndex.is_unique\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2313\u001b[0m \u001b[38;5;129m@cache_readonly\u001b[39m\n\u001b[1;32m   2314\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mis_unique\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mbool\u001b[39m:\n\u001b[1;32m   2315\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   2316\u001b[0m \u001b[38;5;124;03m    Return if the index has unique values.\u001b[39;00m\n\u001b[1;32m   2317\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2344\u001b[0m \u001b[38;5;124;03m    True\u001b[39;00m\n\u001b[1;32m   2345\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 2346\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241m.\u001b[39mis_unique\n",
      "File \u001b[0;32mproperties.pyx:36\u001b[0m, in \u001b[0;36mpandas._libs.properties.CachedProperty.__get__\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/indexes/base.py:889\u001b[0m, in \u001b[0;36mIndex._engine\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    885\u001b[0m     target_values \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_data\u001b[38;5;241m.\u001b[39m_ndarray  \u001b[38;5;66;03m# type: ignore[union-attr]\u001b[39;00m\n\u001b[1;32m    887\u001b[0m \u001b[38;5;66;03m# error: Argument 1 to \"ExtensionEngine\" has incompatible type\u001b[39;00m\n\u001b[1;32m    888\u001b[0m \u001b[38;5;66;03m# \"ndarray[Any, Any]\"; expected \"ExtensionArray\"\u001b[39;00m\n\u001b[0;32m--> 889\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine_type\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtarget_values\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "test = test_raw\n",
    "test = clean_and_merge_datasets(test)\n",
    "test = name_onehot(test)\n",
    "test = drop_unnecessary_columns(test)\n",
    "test, _ = min_max_normalize(test)\n",
    "test = divide_dataframe(test)\n",
    "\n",
    "test, _ = list_to_numpy(test)\n",
    "\n",
    "os.makedirs(\"datas\", exist_ok=True)\n",
    "np.save(\"datas/test.npy\", test)\n",
    "test = np.load(\"datas/test.npy\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
