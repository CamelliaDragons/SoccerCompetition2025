{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HYPER PARAM\n",
    "PROJECT_NAME = \"RobocupTrajectoryPrediction_DataExpanded\"  # wandbのプロジェクト名\n",
    "GROUP_NAME = \"BiGRU\"  # wandbのグループ名\n",
    "MODEL_NAME = \"BiGRU_dataExpanded_5\"  # 保存時のファイル名\n",
    "BATCH_SIZE = 512\n",
    "EPOCHS = 100\n",
    "HIDDEN_DIM = 128\n",
    "NUM_LAYER = 4\n",
    "LEARNING_RATE = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "import os\n",
    "\n",
    "import visualizer\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "import datasets\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from torch import nn\n",
    "import torchmetrics\n",
    "import pytorch_lightning as pl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_float32_matmul_precision(\"high\")\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MinMax:\n",
    "    def __init__(self, min, max):\n",
    "        self.min = min\n",
    "        self.max = max\n",
    "        if self.min >= self.max:\n",
    "            raise ValueError(\"min must be less than max\")\n",
    "\n",
    "    def __call__(self, x):\n",
    "        return (x - self.min) / (self.max - self.min)\n",
    "\n",
    "    def inverse(self, x):\n",
    "        return x * (self.max - self.min) + self.min\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f\"MinMax({self.min}, {self.max})\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = np.load(\"datas/train.npy\")\n",
    "cols = np.load(\"datas/cols.npy\", allow_pickle=True)\n",
    "min_max_d = np.load(\"datas/min_max_d.npy\", allow_pickle=True).item()\n",
    "test = np.load(\"datas/test.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = train[:, :20, :], train[:, 20:, :]\n",
    "X_test, y_test = test[:, :20, :], test[:, 20:, :]\n",
    "\n",
    "print(X_train.shape, y_train.shape, X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EuclideanDistance(torchmetrics.Metric):\n",
    "    \"\"\"\n",
    "    終端誤差を計算する\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, cols, min_max_d, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.cols = cols\n",
    "        self.min_max_d = min_max_d\n",
    "        self.add_state(\"sum\", default=torch.tensor(0.0), dist_reduce_fx=\"sum\")\n",
    "        self.add_state(\"count\", default=torch.tensor(0), dist_reduce_fx=\"sum\")\n",
    "        self._mins = torch.tensor(\n",
    "            [min_max_d[col].min for col in cols], dtype=torch.float32\n",
    "        )\n",
    "        self._maxs = torch.tensor(\n",
    "            [min_max_d[col].max for col in cols], dtype=torch.float32\n",
    "        )\n",
    "        self._scale = self._maxs - self._mins\n",
    "\n",
    "    def update(self, preds, target):\n",
    "        indices = torch.cat([torch.tensor([0]), torch.arange(5, 201, 9)])\n",
    "        final_preds = preds[:, -1, :]\n",
    "        final_target = target[:, -1, :]\n",
    "\n",
    "        inversed_preds = torch.zeros_like(final_preds)\n",
    "        inversed_target = torch.zeros_like(final_target)\n",
    "\n",
    "        mins = self._mins.to(device=device, dtype=final_preds.dtype)\n",
    "        scale = self._scale.to(device=device, dtype=final_preds.dtype)\n",
    "\n",
    "        inversed_preds = final_preds.clone()\n",
    "        inversed_target = final_target.clone()\n",
    "        n_cols = len(self.cols)\n",
    "        inversed_preds[:, :n_cols] = final_preds[:, :n_cols] * scale + mins\n",
    "        inversed_target[:, :n_cols] = final_target[:, :n_cols] * scale + mins\n",
    "\n",
    "        errors = torch.sqrt(\n",
    "            (inversed_preds[:, indices] - inversed_target[:, indices]) ** 2\n",
    "            + (inversed_preds[:, indices + 1] - inversed_target[:, indices + 1]) ** 2\n",
    "        )\n",
    "        self.sum += torch.sum(errors)\n",
    "        self.count += errors.size(0)\n",
    "\n",
    "    def compute(self):\n",
    "        return self.sum / self.count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train, dtype=torch.float32)\n",
    "X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
    "y_test_tensor = torch.tensor(y_test, dtype=torch.float32)\n",
    "\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_dataset, batch_size=BATCH_SIZE, shuffle=True, pin_memory=True, num_workers=16\n",
    ")\n",
    "val_loader = DataLoader(\n",
    "    test_dataset, batch_size=BATCH_SIZE, shuffle=False, pin_memory=True, num_workers=16\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "from pytorch_lightning.loggers import WandbLogger\n",
    "\n",
    "\n",
    "class LitBiGRU(pl.LightningModule):\n",
    "    def __init__(\n",
    "        self, input_dim, hidden_dim, output_dim, num_layers, seq_length, lr=0.001\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "        self.gru = nn.GRU(\n",
    "            input_size=input_dim,\n",
    "            hidden_size=hidden_dim,\n",
    "            num_layers=num_layers,\n",
    "            batch_first=True,\n",
    "            bidirectional=True,\n",
    "        )\n",
    "        self.fc = nn.Linear(hidden_dim * 2, output_dim * seq_length)\n",
    "        self.criterion = nn.MSELoss()\n",
    "        self.euclidean_distance = EuclideanDistance(cols, min_max_d)\n",
    "        self.train_losses = []\n",
    "        self.val_losses = []\n",
    "\n",
    "    def forward(self, x):\n",
    "        out, _ = self.gru(x)\n",
    "        last_out = out[:, -1, :]\n",
    "        output = self.fc(last_out)\n",
    "        return output.view(-1, 30, self.hparams.output_dim)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_hat = self(x)\n",
    "        loss = self.criterion(y_hat, y)\n",
    "        self.log(\"train_loss\", loss, on_step=False, on_epoch=True)\n",
    "        self.log(\n",
    "            \"train_euclidean_distance\",\n",
    "            self.euclidean_distance(y_hat, y),\n",
    "            on_step=False,\n",
    "            on_epoch=True,\n",
    "        )\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_hat = self(x)\n",
    "        loss = self.criterion(y_hat, y)\n",
    "        self.log(\"val_loss\", loss, on_step=False, on_epoch=True)\n",
    "        self.log(\n",
    "            \"val_euclidean_distance\",\n",
    "            self.euclidean_distance(y_hat, y),\n",
    "            on_step=False,\n",
    "            on_epoch=True,\n",
    "        )\n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=self.hparams.lr)\n",
    "        return optimizer\n",
    "\n",
    "\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    monitor=\"val_euclidean_distance\",\n",
    "    dirpath=f\"checkpoints/{MODEL_NAME}\",\n",
    "    filename=\"bilstm-{epoch:02d}-{val_euclidean_distance:.4f}\",\n",
    "    save_top_k=3,\n",
    "    mode=\"min\",\n",
    ")\n",
    "\n",
    "wandb_logger = WandbLogger(\n",
    "    project=PROJECT_NAME,\n",
    "    log_model=True,\n",
    "    save_code=True,\n",
    "    save_dir=\"logs/\",\n",
    "    name=MODEL_NAME,\n",
    "    group=GROUP_NAME,\n",
    ")\n",
    "\n",
    "\n",
    "trainer = pl.Trainer(\n",
    "    max_epochs=EPOCHS,\n",
    "    accelerator=\"gpu\",\n",
    "    devices=1,\n",
    "    callbacks=[checkpoint_callback],\n",
    "    logger=wandb_logger,  # wandbを使わない場合はコメントアウトしてください\n",
    ")\n",
    "\n",
    "input_dim = X_train.shape[2]\n",
    "hidden_dim = HIDDEN_DIM\n",
    "output_dim = y_train.shape[2]\n",
    "seq_length = y_train.shape[1]\n",
    "num_layers = NUM_LAYER\n",
    "learning_rate = LEARNING_RATE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LitBiGRU(\n",
    "    input_dim, hidden_dim, output_dim, num_layers, seq_length, lr=learning_rate\n",
    ")\n",
    "trainer.fit(model, train_loader, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# モデルの保存\n",
    "import time\n",
    "\n",
    "best_model_path = checkpoint_callback.best_model_path\n",
    "model = LitBiGRU.load_from_checkpoint(best_model_path)\n",
    "file_name = f\"{MODEL_NAME}_{time.strftime('%Y%m%d%H%M%S')}.pth\"\n",
    "\n",
    "os.makedirs(f\"models/{MODEL_NAME}\", exist_ok=True)\n",
    "torch.save(model.state_dict(), f\"models/{MODEL_NAME}/{file_name}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
